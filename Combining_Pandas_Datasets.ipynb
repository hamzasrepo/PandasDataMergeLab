{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Y94xhI5k3YsS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Combining Datasets: Concat**\n",
        "\n",
        "Concatenation of $\\small\\texttt{Series}$ and $\\small\\texttt{DataFrame}$ objects is very similar to concatenation of NumPy arrays, which can be done via the $\\small\\texttt{np.concatenate}$ function"
      ],
      "metadata": {
        "id": "-0TggwPI2irN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arPDIHO_2fVu"
      },
      "outputs": [],
      "source": [
        "x = [1, 2, 3]\n",
        "y = [4, 5, 6]\n",
        "z = [7, 8, 9]\n",
        "np.concatenate([x, y, z])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first argument is a list or tuple of arrays to concatenate. Additionally, it takes an $\\small\\texttt{axis}$ keyword that allows you to specify the axis along which the result will be concatenated:"
      ],
      "metadata": {
        "id": "DS7dFnE-3se_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = [[1, 2], [3, 4]]\n",
        "print(np.concatenate([x, x], axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_HBp2Hh30vH",
        "outputId": "19d083af-8180-432f-e15c-327e6dd12ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 1 2]\n",
            " [3 4 3 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at simple concatenation of $\\small\\texttt{Series}$ and $\\small\\texttt{DataFrames}$ with the $\\small\\texttt{pd.concat}$ function. For convenience, we’ll define this function, which creates a $\\small\\texttt{DataFrame}$ of a particular form that will be useful below:"
      ],
      "metadata": {
        "id": "XWJq70toJHjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_df(cols, ind):\n",
        "  # Quickly make a DataFrame\n",
        "  data = {c: [str(c) + str(i) for i in ind]\n",
        "          for c in cols}\n",
        "  return pd.DataFrame(data, index=ind)"
      ],
      "metadata": {
        "id": "kjJt47bU3774"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(make_df('ABC', [0, 1, 2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6ugMrAKKoLk",
        "outputId": "026c2a06-09a9-4a15-efb5-55db962a4ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    A   B   C\n",
            "0  A0  B0  C0\n",
            "1  A1  B1  C1\n",
            "2  A2  B2  C2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Simple Concatenation with pd.concat**\n",
        "\n",
        "Pandas has a function, $\\small\\texttt{pd.concat()}$, which has a similar syntax to $\\small\\texttt{np.concatenate}$ but contains a number of other options. $\\small\\texttt{pd.concat()}$ can be used for a simple concatenation of $\\small\\texttt{Series}$ or $\\small\\texttt{DataFrame}$ objects."
      ],
      "metadata": {
        "id": "qpZBFIP_Lkjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenation of Series objects\n",
        "ser1 = pd.Series(list('ABC'), index=range(1, 4))\n",
        "ser2 = pd.Series(list('DEF'), index=range(4, 7))\n",
        "print(pd.concat([ser1, ser2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJmj8lmIL4hw",
        "outputId": "aebcf7a7-6485-470b-b284-2f23764ca423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    A\n",
            "2    B\n",
            "3    C\n",
            "4    D\n",
            "5    E\n",
            "6    F\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenation of DataFrame objects\n",
        "df1 = make_df('AB', [1, 2])\n",
        "df2 = make_df('AB', [3, 4])\n",
        "print(df1); print(df2); print(pd.concat([df1, df2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-e9T4zMM3aj",
        "outputId": "eee3bc39-b545-4a1d-f842-5ea61ed86958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    A   B\n",
            "1  A1  B1\n",
            "2  A2  B2\n",
            "    A   B\n",
            "3  A3  B3\n",
            "4  A4  B4\n",
            "    A   B\n",
            "1  A1  B1\n",
            "2  A2  B2\n",
            "3  A3  B3\n",
            "4  A4  B4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like $\\small\\texttt{np.concatenate}$, $\\small\\texttt{pd.concat}$ allows specification of an axis along which concatenation will take place. By default, the concatenation takes place row-wise within the $\\small\\texttt{DataFrame}$ (i.e., $\\small\\texttt{axis=0}$)."
      ],
      "metadata": {
        "id": "52Dikf1bNz0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = make_df('AB', [0, 1])\n",
        "df4 = make_df('CD', [0, 1])\n",
        "print(df3); print(df4); print(pd.concat([df3, df4], axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dc8QmXZNYq5",
        "outputId": "2cb6a467-8cc7-455c-c07c-8d1f06f5f58f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    A   B\n",
            "0  A0  B0\n",
            "1  A1  B1\n",
            "    C   D\n",
            "0  C0  D0\n",
            "1  C1  D1\n",
            "    A   B   C   D\n",
            "0  A0  B0  C0  D0\n",
            "1  A1  B1  C1  D1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Duplicate indices**\n",
        "\n",
        "One important difference between $\\small\\texttt{np.concatenate}$ and $\\small\\texttt{pd.concat}$ is that Pandas concatenation *preserves indices*, even if the result will have duplicate indices. While this is valid within $\\small\\texttt{DataFrames}$, the outcome is often undesirable."
      ],
      "metadata": {
        "id": "ie_rdiUuO5lX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = make_df('AB', [0, 1])\n",
        "y = make_df('AB', [3, 4])\n",
        "y.index = x.index # Make duplicate indices"
      ],
      "metadata": {
        "id": "RE_uWmRXT6BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x); print(y); print(pd.concat([x, y]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C863w_7jPN3s",
        "outputId": "f68cbc4a-b553-45c1-ebdb-3fb9bc35ccd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    A   B\n",
            "0  A0  B0\n",
            "1  A1  B1\n",
            "    A   B\n",
            "0  A3  B3\n",
            "1  A4  B4\n",
            "    A   B\n",
            "0  A0  B0\n",
            "1  A1  B1\n",
            "0  A3  B3\n",
            "1  A4  B4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Catching the repeats as an error**\n",
        "\n",
        "If you’d like to simply verify that the indices in the result of $\\small\\texttt{pd.concat()}$ do not overlap, you can specify the $\\small\\texttt{verify_integrity}$ flag. Setting it to $\\small\\texttt{True}$, the concatenation will raise an exception if there are duplicate indices."
      ],
      "metadata": {
        "id": "xixWP7ncQKUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  pd.concat([x, y], verify_integrity=True)\n",
        "except ValueError as e:\n",
        "  print(f'ValueError: {e}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXNKAv6FQc4F",
        "outputId": "4a9e8a28-5515-4a4e-99da-fc141dab412f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError: Indexes have overlapping values: Int64Index([0, 1], dtype='int64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ignoring the index**\n",
        "\n",
        "Sometimes the index itself does not matter, and you would prefer it to simply be ignored. You can do that using the $\\small\\texttt{ignore_index}$ flag. Setting it to $\\small\\texttt{True}$, the concatenation will create a new integer index for the resulting $\\small\\texttt{Series}$:"
      ],
      "metadata": {
        "id": "DKFjT3NkRRPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x); print(y); print(pd.concat([x, y], ignore_index=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_aQ2GPhRuik",
        "outputId": "372cbeef-f2c4-4169-a33e-22e70e49eee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    A   B\n",
            "0  A0  B0\n",
            "1  A1  B1\n",
            "    A   B\n",
            "0  A3  B3\n",
            "1  A4  B4\n",
            "    A   B\n",
            "0  A0  B0\n",
            "1  A1  B1\n",
            "2  A3  B3\n",
            "3  A4  B4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Adding MultiIndex keys**\n",
        "\n",
        "Another alternative is to use the $\\small\\texttt{keys}$ option to specify a label for the data sources; the result will be a hierarchically indexed series containing the data:"
      ],
      "metadata": {
        "id": "xEFx1mYISZ7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x); print(y); print(pd.concat([x, y], keys=['x', 'y']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCHdKg3MSXsL",
        "outputId": "cb77953a-cdde-4967-aad3-e1d3b26d5416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    A   B\n",
            "0  A0  B0\n",
            "1  A1  B1\n",
            "    A   B\n",
            "0  A3  B3\n",
            "1  A4  B4\n",
            "      A   B\n",
            "x 0  A0  B0\n",
            "  1  A1  B1\n",
            "y 0  A3  B3\n",
            "  1  A4  B4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Concatenation with joins**\n",
        "\n",
        "So far, we were mainly concatenating $\\small\\texttt{DataFrames}$ with shared column names. In practice, data from different sources might have different sets of column names, and $\\small\\texttt{pd.concat}$ offers several options in this case."
      ],
      "metadata": {
        "id": "rTNE7lyl-d6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = make_df('ABC', [1, 2])\n",
        "df6 = make_df('BCD', [3, 4])\n",
        "print(df5); print(df6); print(pd.concat([df5, df6]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfThORBA_N_Z",
        "outputId": "931a428b-8dd3-4d76-f149-880faec33132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    A   B   C\n",
            "1  A1  B1  C1\n",
            "2  A2  B2  C2\n",
            "    B   C   D\n",
            "3  B3  C3  D3\n",
            "4  B4  C4  D4\n",
            "     A   B   C    D\n",
            "1   A1  B1  C1  NaN\n",
            "2   A2  B2  C2  NaN\n",
            "3  NaN  B3  C3   D3\n",
            "4  NaN  B4  C4   D4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the entries for which no data is available are filled with NA values. To change this, we can specify one of several options for the $\\small\\texttt{join}$ parameter of the concatenate function. By default, the join is a union of the input columns $\\small\\texttt{(join='outer')}$, but we can change this to an intersection of the columns using $\\small\\texttt{join='inner'}$."
      ],
      "metadata": {
        "id": "QrwbfySEAozZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df5); print(df6); print(pd.concat([df5, df6], join='inner'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQeszPOyA1jq",
        "outputId": "77b1dcf0-8fb8-49e9-88c7-e8353128b305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    A   B   C\n",
            "1  A1  B1  C1\n",
            "2  A2  B2  C2\n",
            "    B   C   D\n",
            "3  B3  C3  D3\n",
            "4  B4  C4  D4\n",
            "    B   C\n",
            "1  B1  C1\n",
            "2  B2  C2\n",
            "3  B3  C3\n",
            "4  B4  C4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Combining Datasets: Merge and Join**\n",
        "\n",
        "One essential feature offered by Pandas is its high-performance, in-memory join and merge operations. The main interface for this is the $\\small\\texttt{pd.merge}$ function."
      ],
      "metadata": {
        "id": "ZYHr2bDGFoMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Categories of Joins**\n",
        "\n",
        "The $\\small\\texttt{pd.merge()}$ function implements a number of types of joins: the *one-to-one*, *many-to-one*, and *many-to-many* joins. All three types of joins are accessed via an identical call to the $\\small\\texttt{pd.merge()}$ interface; the type of join performed depends on the form of the input data."
      ],
      "metadata": {
        "id": "DXr8dt-uF7XL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **One-to-one joins**\n",
        "\n",
        "Perhaps the simplest type of merge expression is the one-to-one join, which is in many ways very similar to the column-wise concatenation. To combine the columns of two $\\small\\texttt{DataFrames}$ into a single $\\small\\texttt{DataFrame}$, we can use the $\\small\\texttt{pd.merge()}$ function."
      ],
      "metadata": {
        "id": "CgojAd5VHCjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame({'employee': ['John', 'Mary', 'David', 'Emma'],\n",
        "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
        "df2 = pd.DataFrame({'employee': ['David', 'John', 'Mary', 'Emma'],\n",
        "                    'hire_date': [2004, 2008, 2012, 2014]})\n",
        "print(df1); print(df2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nciFVhr_G_sC",
        "outputId": "cdd07556-09f6-40c7-aad7-ff10680d088f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  employee        group\n",
            "0     John   Accounting\n",
            "1     Mary  Engineering\n",
            "2    David  Engineering\n",
            "3     Emma           HR\n",
            "  employee  hire_date\n",
            "0    David       2004\n",
            "1     John       2008\n",
            "2     Mary       2012\n",
            "3     Emma       2014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.merge(df1, df2)\n",
        "print(df3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJlDQi2FJHAP",
        "outputId": "4d89abe5-1531-4dca-ce14-2cc342f1eb75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  employee        group  hire_date\n",
            "0     John   Accounting       2008\n",
            "1     Mary  Engineering       2012\n",
            "2    David  Engineering       2004\n",
            "3     Emma           HR       2014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The $\\small\\texttt{pd.merge()}$ function recognizes that each $\\small\\texttt{DataFrame}$ has an “employee” column, and automatically joins using this column as a key. The result of the merge is a new $\\small\\texttt{DataFrame}$ that combines the information from the two inputs."
      ],
      "metadata": {
        "id": "swB5h1XnJg3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Many-to-one joins**\n",
        "\n",
        "Many-to-one joins are joins in which one of the two key columns contains duplicate entries. For the many-to-one case, the resulting $\\small\\texttt{DataFrame}$ will preserve those duplicate entries as appropriate."
      ],
      "metadata": {
        "id": "bxTAbfhTKB_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'],\n",
        "                    'supervisor': ['Carly', 'Gustav', 'Steve']})\n",
        "print(df3); print(df4); print(pd.merge(df3, df4))"
      ],
      "metadata": {
        "id": "NtUJO01xJ5WY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c436198-d773-4435-dbc0-b42c21b09ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  employee        group  hire_date\n",
            "0     John   Accounting       2008\n",
            "1     Mary  Engineering       2012\n",
            "2    David  Engineering       2004\n",
            "3     Emma           HR       2014\n",
            "         group supervisor\n",
            "0   Accounting      Carly\n",
            "1  Engineering     Gustav\n",
            "2           HR      Steve\n",
            "  employee        group  hire_date supervisor\n",
            "0     John   Accounting       2008      Carly\n",
            "1     Mary  Engineering       2012     Gustav\n",
            "2    David  Engineering       2004     Gustav\n",
            "3     Emma           HR       2014      Steve\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Many-to-many joins**\n",
        "\n",
        "If the key column in both the left and right array contains duplicates, then\n",
        "the result is a many-to-many merge. Consider the following, where we have a $\\small\\texttt{DataFrame}$ showing one or more skills associated with a particular group.\n",
        "\n",
        "By performing a many-to-many join, we can recover the skills associated with any individual person:"
      ],
      "metadata": {
        "id": "Q_WuiY3Ygh8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = pd.DataFrame({'group': ['Accounting', 'Accounting',\n",
        "                              'Engineering', 'Engineering', 'HR', 'HR'],\n",
        "                    'skills': ['math', 'spreadsheets', 'coding', 'linux',\n",
        "                               'spreadsheets', 'organization']})\n",
        "print(df1), print(df5), print(pd.merge(df1, df5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyM2zOs4hItG",
        "outputId": "cf1aaee7-5914-47c1-c83d-03a4f1905a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  employee        group\n",
            "0     John   Accounting\n",
            "1     Mary  Engineering\n",
            "2    David  Engineering\n",
            "3     Emma           HR\n",
            "         group        skills\n",
            "0   Accounting          math\n",
            "1   Accounting  spreadsheets\n",
            "2  Engineering        coding\n",
            "3  Engineering         linux\n",
            "4           HR  spreadsheets\n",
            "5           HR  organization\n",
            "  employee        group        skills\n",
            "0     John   Accounting          math\n",
            "1     John   Accounting  spreadsheets\n",
            "2     Mary  Engineering        coding\n",
            "3     Mary  Engineering         linux\n",
            "4    David  Engineering        coding\n",
            "5    David  Engineering         linux\n",
            "6     Emma           HR  spreadsheets\n",
            "7     Emma           HR  organization\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Specification of the Merge Key**\n",
        "\n",
        "We’ve already seen the default behavior of $\\small\\texttt{pd.merge()}$: it looks for one or more matching column names between the two inputs, and uses this as the key. However, often the column names will not match so nicely, and $\\small\\texttt{pd.merge()}$ provides a variety of options to handle this."
      ],
      "metadata": {
        "id": "NbV2ppdwt7CK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **The on keyword**\n",
        "\n",
        "Most simply, you can explicitly specify the name of the key column using the $\\small\\texttt{on}$ keyword, which takes a column name or a list of column names. This option works only if both the left and right $\\small\\texttt{DataFrames}$ have the specified column name."
      ],
      "metadata": {
        "id": "NRSMgKzyuPxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1); print(df2); print(pd.merge(df1, df2, on='employee'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43wouhcZuiKL",
        "outputId": "5de650d5-7f0e-439a-cf36-96bfd13078c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  employee        group\n",
            "0     John   Accounting\n",
            "1     Mary  Engineering\n",
            "2    David  Engineering\n",
            "3     Emma           HR\n",
            "  employee  hire_date\n",
            "0    David       2004\n",
            "1     John       2008\n",
            "2     Mary       2012\n",
            "3     Emma       2014\n",
            "  employee        group  hire_date\n",
            "0     John   Accounting       2008\n",
            "1     Mary  Engineering       2012\n",
            "2    David  Engineering       2004\n",
            "3     Emma           HR       2014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **The left_on and right_on keywords**\n",
        "\n",
        "At times you may wish to merge two datasets with different column names; e.g., we may have a dataset in which the employee name is labeled as “name” rather\n",
        "than “employee”. In this case, we can use the $\\small\\texttt{left_on}$ and $\\small\\texttt{right_on keywords}$ to specify the two column names.\n"
      ],
      "metadata": {
        "id": "X2h_MhmjvFgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.DataFrame({'name': ['John', 'Mary', 'David', 'Emma'],\n",
        "                    'salary': [70000, 80000, 120000, 90000]})\n",
        "print(df1); print(df3);\n",
        "print(pd.merge(df1, df3, left_on='employee', right_on='name'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovmGH6qSvIfm",
        "outputId": "449cd734-c7ad-4ad9-bd3c-ee7bc893905f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  employee        group\n",
            "0     John   Accounting\n",
            "1     Mary  Engineering\n",
            "2    David  Engineering\n",
            "3     Emma           HR\n",
            "    name  salary\n",
            "0   John   70000\n",
            "1   Mary   80000\n",
            "2  David  120000\n",
            "3   Emma   90000\n",
            "  employee        group   name  salary\n",
            "0     John   Accounting   John   70000\n",
            "1     Mary  Engineering   Mary   80000\n",
            "2    David  Engineering  David  120000\n",
            "3     Emma           HR   Emma   90000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result has a redundant column that we can drop if desired—for example, by\n",
        "using the $\\small\\texttt{drop()}$ method of $\\small\\texttt{DataFrames}$."
      ],
      "metadata": {
        "id": "u8n4FrBev-5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.merge(df1, df3, left_on='employee', right_on='name').drop('name', axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa43Y0r_wFhR",
        "outputId": "f151df03-aaca-40cf-c8d1-46f9b8dc9186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  employee        group  salary\n",
            "0     John   Accounting   70000\n",
            "1     Mary  Engineering   80000\n",
            "2    David  Engineering  120000\n",
            "3     Emma           HR   90000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **The left_index and right_index keywords**\n",
        "\n",
        "Sometimes, rather than merging on a column, you would instead like to merge on an index. Let's set the $\\small\\texttt{employee}$ column as the indices of the $\\small\\texttt{DataFrames}$, $\\small\\texttt{df1}$ and $\\small\\texttt{df2}$ using the $\\small\\texttt{set_index}$ method."
      ],
      "metadata": {
        "id": "-L-ST9gCw77W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1a = df1.set_index('employee')\n",
        "df2a = df2.set_index('employee')\n",
        "print(df1a); print(df2a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbGwuJXfxWh2",
        "outputId": "cd12aad5-2de5-4643-e4f7-8d3a6f49806f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                group\n",
            "employee             \n",
            "John       Accounting\n",
            "Mary      Engineering\n",
            "David     Engineering\n",
            "Emma               HR\n",
            "          hire_date\n",
            "employee           \n",
            "David          2004\n",
            "John           2008\n",
            "Mary           2012\n",
            "Emma           2014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the index as the key for merging by specifying the $\\small\\texttt{left_index}$ and/or $\\small\\texttt{right_index}$ flags in $\\small\\texttt{pd.merge()}$."
      ],
      "metadata": {
        "id": "EnikZZhyxzO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.merge(df1a, df2a, left_index=True, right_index=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al-qu28Qx9Du",
        "outputId": "363005a2-6950-43b4-b8ec-91081b65014a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                group  hire_date\n",
            "employee                        \n",
            "John       Accounting       2008\n",
            "Mary      Engineering       2012\n",
            "David     Engineering       2004\n",
            "Emma               HR       2014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For convenience, $\\small\\texttt{DataFrames}$ implement the $\\small\\texttt{join()}$ method, which performs a merge that defaults to joining on indices:"
      ],
      "metadata": {
        "id": "-KTVfUccyVw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1a); print(df2a); print(df1a.join(df2a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1uqHymLyVfQ",
        "outputId": "9d0056b0-4077-4503-a2d2-174f10a0286f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                group\n",
            "employee             \n",
            "John       Accounting\n",
            "Mary      Engineering\n",
            "David     Engineering\n",
            "Emma               HR\n",
            "          hire_date\n",
            "employee           \n",
            "David          2004\n",
            "John           2008\n",
            "Mary           2012\n",
            "Emma           2014\n",
            "                group  hire_date\n",
            "employee                        \n",
            "John       Accounting       2008\n",
            "Mary      Engineering       2012\n",
            "David     Engineering       2004\n",
            "Emma               HR       2014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Specifying Set Arithmetic for Joins**\n",
        "\n",
        "One important consideration in performing a join is the type of set arithmetic used in the join. This comes up when a value appears in one key column but not the other."
      ],
      "metadata": {
        "id": "0KnHmXl-zi6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df6 = pd.DataFrame({'name': ['Daniel', 'Peter', 'Jessica'],\n",
        "                    'food': ['fish', 'beans', 'bread']})\n",
        "df7 = pd.DataFrame({'name': ['Jessica', 'Joseph'],\n",
        "                    'drink': ['wine', 'beer']})\n",
        "print(df6); print(df7); print(pd.merge(df6, df7))"
      ],
      "metadata": {
        "id": "eIWBPrsbzmeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "385e6568-095e-49f7-a7e2-5c292b4c34d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    name   food\n",
            "0  Peter   fish\n",
            "1   Paul  beans\n",
            "2   Mary  bread\n",
            "     name drink\n",
            "0    Mary  wine\n",
            "1  Joseph  beer\n",
            "   name   food drink\n",
            "0  Mary  bread  wine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have merged two datasets that have only a single “name” entry in common:\n",
        "Jessica. By default, the result contains the *intersection* of the two sets of inputs; this is what is known as an *inner join*. We can specify this explicitly using the $\\small\\texttt{how}$ keyword, which defaults to $\\small\\texttt{'inner'}$:"
      ],
      "metadata": {
        "id": "GoVoJXJDSPKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.merge(df6, df7, how='inner'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lynMVM67SOyv",
        "outputId": "622d57a3-1231-4cef-cbba-c7c412ca7531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   name   food drink\n",
            "0  Mary  bread  wine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other options for the how keyword are $\\small\\texttt{'outer'}$, $\\small\\texttt{'left'}$, and $\\small\\texttt{'right'}$. An *outer* join returns a join over the union of the input columns, and fills in all missing values with NAs."
      ],
      "metadata": {
        "id": "82BmTxYaSwt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df6); print(df7); print(pd.merge(df6, df7, how='outer'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G-vGs7CS6A9",
        "outputId": "d2948a74-8f28-4599-9ba7-0d4a8396cb89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    name   food\n",
            "0  Peter   fish\n",
            "1   Paul  beans\n",
            "2   Mary  bread\n",
            "     name drink\n",
            "0    Mary  wine\n",
            "1  Joseph  beer\n",
            "     name   food drink\n",
            "0   Peter   fish   NaN\n",
            "1    Paul  beans   NaN\n",
            "2    Mary  bread  wine\n",
            "3  Joseph    NaN  beer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *left join* and *right join* return join over the left entries and right entries, respectively."
      ],
      "metadata": {
        "id": "XBrjaC21TE89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df6); print(df7)\n",
        "print(pd.merge(df6, df7, how='left'))\n",
        "print(pd.merge(df6, df7, how='right'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f0yYVGzTJ4U",
        "outputId": "b1f1e356-8506-4bea-e976-9ad160c5b094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    name   food\n",
            "0  Peter   fish\n",
            "1   Paul  beans\n",
            "2   Mary  bread\n",
            "     name drink\n",
            "0    Mary  wine\n",
            "1  Joseph  beer\n",
            "    name   food drink\n",
            "0  Peter   fish   NaN\n",
            "1   Paul  beans   NaN\n",
            "2   Mary  bread  wine\n",
            "     name   food drink\n",
            "0    Mary  bread  wine\n",
            "1  Joseph    NaN  beer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Overlapping Column Names: The suffixes Keyword**\n",
        "\n",
        "At times, You may end up in a case where your two input $\\small\\texttt{DataFrames}$ have conflicting column names."
      ],
      "metadata": {
        "id": "brRapPwtT2Wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df8 = pd.DataFrame({'name': ['David', 'Jacob', 'Jason', 'Danny'],\n",
        "                   'rank': [1, 2, 3, 4]})\n",
        "df9 = pd.DataFrame({'name': ['David', 'Jacob', 'Jason', 'Danny'],\n",
        "                   'rank': [3, 1, 4, 2]})\n",
        "print(df8); print(df9); print(pd.merge(df8, df9, on='name'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkUwv6xAUXOx",
        "outputId": "6d4967c0-1d81-4e6d-cff4-49a6a2004b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    name  rank\n",
            "0  David     1\n",
            "1  Jacob     2\n",
            "2  Jason     3\n",
            "3  Danny     4\n",
            "    name  rank\n",
            "0  David     3\n",
            "1  Jacob     1\n",
            "2  Jason     4\n",
            "3  Danny     2\n",
            "    name  rank_x  rank_y\n",
            "0  David       1       3\n",
            "1  Jacob       2       1\n",
            "2  Jason       3       4\n",
            "3  Danny       4       2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the output would have two conflicting column names, the merge function\n",
        "automatically appends a suffix $\\small\\texttt{_x}$ or $\\small\\texttt{_y}$ to make the output columns unique. To change the defaults, you can specify a custom suffix using the $\\small\\texttt{suffixes}$ keyword. These suffixes work in any of the possible join patterns, and work also if there are\n",
        "multiple overlapping columns."
      ],
      "metadata": {
        "id": "PqArTAWqVAuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df8); print(df9)\n",
        "print(pd.merge(df8, df9, on='name', suffixes=['_L', '_R']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdswBRYfVRtc",
        "outputId": "a12f6111-1450-4393-dcae-2426fbca4ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    name  rank\n",
            "0  David     1\n",
            "1  Jacob     2\n",
            "2  Jason     3\n",
            "3  Danny     4\n",
            "    name  rank\n",
            "0  David     3\n",
            "1  Jacob     1\n",
            "2  Jason     4\n",
            "3  Danny     2\n",
            "    name  rank_L  rank_R\n",
            "0  David       1       3\n",
            "1  Jacob       2       1\n",
            "2  Jason       3       4\n",
            "3  Danny       4       2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Project: US States Data**\n",
        "\n",
        "Merge and join operations come up most often when one is combining data from different sources. Here we will consider an example of some data about US states and their populations. The data files $\\small\\texttt{state-population.csv}$, $\\small\\texttt{state-areas.csv}$, and $\\small\\texttt{state-abbrevs.csv}$ can be found in my very GitHub repository."
      ],
      "metadata": {
        "id": "4-0b7dPuq_6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pop = pd.read_csv('state-population.csv')\n",
        "areas = pd.read_csv('state-areas.csv')\n",
        "abbrevs = pd.read_csv('state-abbrevs.csv')\n",
        "print(pop.head()); print(areas.head()); print(abbrevs.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79ecDy4wroEv",
        "outputId": "7d7f439b-726b-431a-d942-f23bcfbf3c3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  state/region     ages  year  population\n",
            "0           AL  under18  2012   1117489.0\n",
            "1           AL    total  2012   4817528.0\n",
            "2           AL  under18  2010   1130966.0\n",
            "3           AL    total  2010   4785570.0\n",
            "4           AL  under18  2011   1125763.0\n",
            "        state  area (sq. mi)\n",
            "0     Alabama          52423\n",
            "1      Alaska         656425\n",
            "2     Arizona         114006\n",
            "3    Arkansas          53182\n",
            "4  California         163707\n",
            "        state abbreviation\n",
            "0     Alabama           AL\n",
            "1      Alaska           AK\n",
            "2     Arizona           AZ\n",
            "3    Arkansas           AR\n",
            "4  California           CA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given this information, say we want to rank US states and territories by their 2010 population density. We will have to combine the datasets to get it. We’ll start with a many-to-one merge that will give us the full state name within the population $\\small\\texttt{DataFrame}$. We want to merge based on the $\\small\\texttt{state/region}$ column of $\\small\\texttt{pop}$, and the $\\small\\texttt{abbreviation}$ column of $\\small\\texttt{abbrevs}$. We’ll use $\\small\\texttt{how='outer'}$ to make sure no data is thrown away due to mismatched labels."
      ],
      "metadata": {
        "id": "JKgmZrm1sSWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged = pd.merge(pop, abbrevs, how='outer',\n",
        "                  left_on='state/region', right_on='abbreviation')\n",
        "merged = merged.drop('abbreviation', axis=1) # Drop duplicate info\n",
        "print(merged.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuF9obgds3Up",
        "outputId": "c754d2f9-2d62-4af9-9163-a8032e6f4503"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  state/region     ages  year  population    state\n",
            "0           AL  under18  2012   1117489.0  Alabama\n",
            "1           AL    total  2012   4817528.0  Alabama\n",
            "2           AL  under18  2010   1130966.0  Alabama\n",
            "3           AL    total  2010   4785570.0  Alabama\n",
            "4           AL  under18  2011   1125763.0  Alabama\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(merged.isnull().any()) # Checks whether there were any mismatches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4JemE51tfp0",
        "outputId": "65df8302-b656-4313-ea93-f965ea61b743"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state/region    False\n",
            "ages            False\n",
            "year            False\n",
            "population       True\n",
            "state            True\n",
            "dtype: bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of the $\\small\\texttt{population}$ info is null; let’s figure out which these are!"
      ],
      "metadata": {
        "id": "SLkMgf3utxD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(merged[merged['population'].isnull()].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcwfwjJlt2WJ",
        "outputId": "dea682c5-e7ce-4a53-9e2b-708f8c445ba2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     state/region     ages  year  population state\n",
            "2448           PR  under18  1990         NaN   NaN\n",
            "2449           PR    total  1990         NaN   NaN\n",
            "2450           PR    total  1991         NaN   NaN\n",
            "2451           PR  under18  1991         NaN   NaN\n",
            "2452           PR    total  1993         NaN   NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see also that some of the new $\\small\\texttt{state}$ entries are also null, which means that there was no corresponding entry in the $\\small\\texttt{abbrevs}$ key! Let’s figure out which regions lack this match."
      ],
      "metadata": {
        "id": "7DtMkd76uH_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(merged.loc[merged['state'].isnull(), 'state/region'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoaQ1SsXuTdF",
        "outputId": "39f2cfd9-d450-4754-a69a-3a4a6252e94e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PR' 'USA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our population data includes entries for Puerto Rico\n",
        "(PR) and the United States as a whole (USA), while these entries do not appear in the state abbreviation key. We can fix these quickly by filling in appropriate entries."
      ],
      "metadata": {
        "id": "eVwl1tKpuyAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged.loc[merged['state/region'] == 'PR', 'state'] = 'Puerto Rico'\n",
        "merged.loc[merged['state/region'] == 'USA', 'state'] = 'United States'\n",
        "merged.isnull().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU3UZP7hu108",
        "outputId": "daf6705f-03c4-49d2-ea2d-0a0301cb845d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "state/region    False\n",
              "ages            False\n",
              "year            False\n",
              "population       True\n",
              "state           False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see there are no more $\\small\\texttt{nulls}$ in the state column. Now we can merge the result with the area data using a similar procedure. Examining our results, we will want to join on the $\\small\\texttt{state}$ column in both."
      ],
      "metadata": {
        "id": "xZQIW4BDvb-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final = pd.merge(merged, areas, on='state', how='left')\n",
        "print(final.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyV1PjwNvyMC",
        "outputId": "95480c1e-5922-4e48-d639-189df665bc38"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  state/region     ages  year  population    state  area (sq. mi)\n",
            "0           AL  under18  2012   1117489.0  Alabama        52423.0\n",
            "1           AL    total  2012   4817528.0  Alabama        52423.0\n",
            "2           AL  under18  2010   1130966.0  Alabama        52423.0\n",
            "3           AL    total  2010   4785570.0  Alabama        52423.0\n",
            "4           AL  under18  2011   1125763.0  Alabama        52423.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final.isnull().any() # Check for any mismatches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-A7-MXvwzWr",
        "outputId": "c3ea8539-7b75-4fef-cabe-6188ca25b37b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "state/region     False\n",
              "ages             False\n",
              "year             False\n",
              "population        True\n",
              "state            False\n",
              "area (sq. mi)     True\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final['state'][final['area (sq. mi)'].isnull()].unique() # See which regions were ignored"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ5Jq8mwxB-D",
        "outputId": "ddf834c5-fc88-4acb-aee7-19317f860e5f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['United States'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that our $\\small\\texttt{areas DataFrame}$ does not contain the area of the United States as a whole. We’ll just drop the null values because the population density of the entire United States is not relevant to the current discussion."
      ],
      "metadata": {
        "id": "b0vKGeqYxTsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final.dropna(inplace=True)\n",
        "print(final.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1e6GXXbxjCj",
        "outputId": "d73a0f7f-6e38-4c64-9d4c-44f65bf6debc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  state/region     ages  year  population    state  area (sq. mi)\n",
            "0           AL  under18  2012   1117489.0  Alabama        52423.0\n",
            "1           AL    total  2012   4817528.0  Alabama        52423.0\n",
            "2           AL  under18  2010   1130966.0  Alabama        52423.0\n",
            "3           AL    total  2010   4785570.0  Alabama        52423.0\n",
            "4           AL  under18  2011   1125763.0  Alabama        52423.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the population density of each state, let’s first select the portion of the data corresponding with the year 2010, and the total population. We’ll use the $\\small\\texttt{query()}$ function to do this quickly."
      ],
      "metadata": {
        "id": "D4OdbaDfx5qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2010 = final.query('year == 2010 & ages == \\'total\\'')\n",
        "print(data2010.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2pE2s8dyDHf",
        "outputId": "81d1c5ee-85dc-416f-defa-ccc830ced4a8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    state/region   ages  year  population       state  area (sq. mi)\n",
            "3             AL  total  2010   4785570.0     Alabama        52423.0\n",
            "91            AK  total  2010    713868.0      Alaska       656425.0\n",
            "101           AZ  total  2010   6408790.0     Arizona       114006.0\n",
            "189           AR  total  2010   2922280.0    Arkansas        53182.0\n",
            "197           CA  total  2010  37333601.0  California       163707.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s compute the population density and display it in order. We’ll start by reindexing our data on the state, and then compute the result."
      ],
      "metadata": {
        "id": "IniEco9vylG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2010.set_index('state', inplace=True)\n",
        "density = data2010['population'] / data2010['area (sq. mi)']\n",
        "\n",
        "density.sort_values(ascending=False, inplace=True)\n",
        "density.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEqeRzfQynHc",
        "outputId": "95aae15f-08a3-4aac-d555-f351a525a601"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "state\n",
              "District of Columbia    8898.897059\n",
              "Puerto Rico             1058.665149\n",
              "New Jersey              1009.253268\n",
              "Rhode Island             681.339159\n",
              "Connecticut              645.600649\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that by far the densest region in this dataset is Washington, DC (i.e., the District of Columbia); among states, the densest is New Jersey.\n",
        "\n",
        "We can also check the least dense states."
      ],
      "metadata": {
        "id": "1ueKorakzLEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(density.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBkejOKTzZQo",
        "outputId": "ada44a21-0f74-4f2c-e27d-234b1bd01b7d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state\n",
            "South Dakota    10.583512\n",
            "North Dakota     9.537565\n",
            "Montana          6.736171\n",
            "Wyoming          5.768079\n",
            "Alaska           1.087509\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the least dense state, by far, is Alaska."
      ],
      "metadata": {
        "id": "npXeVlcLzfMS"
      }
    }
  ]
}